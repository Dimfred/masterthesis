\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces All used \acp {ECC} in this thesis in German notation: 1. Voltage Source, 2. Current Source, 3. Resistor, 4. Inductor, 5. Capacitor, 6. Diode, 7. Ground\relax }}{3}{}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces A MLP with two hidden layers (two neurons in the first and one in the last), each input gets multiplied with each weight of each neuron, summed up and fed into an activation function to produce the input for the next layer, where this process is repeated.\relax }}{8}{}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Example convolution of a 4x4 input (blue) with a 3x3 kernel (dark blue) and a stride of 1, resulting in a 2x2 output (cyan) \cite {conv_arithmetic}\relax }}{12}{}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Example of results obtained through the Selective Search algorithm (top) with increasing region scale from left to right and bounding boxes drawn around those regions (bottom). Selective Search produces sub-segmentations of objects in an image, considering size, color, texture and shape based features for the grouping of the regions. \cite {selective_search}\relax }}{15}{}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Bounding box calculation in the YOLOv4 network based on a prior anchor box \cite {yolov2}. The $b_*$ indicate the final prediction, $p_*$ indicate parameters of the prior bounding box and $c_*$ indicate the prior bounding box spatial offset based on the current cell. The final center coordinate offset is predicted non-linearly with a sigmoid function, while the final width and height are predicted linearly, as it is done in \cite {fast_rcnn} and \cite {faster_rcnn}.\relax }}{23}{}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces The difference between object detection, semantic segmentation and instance segmentation. In object detection the instance with a rough estimate (bounding box) is predicted, in semantic segmentation a segmentation mask for an object is predicted without considering the underlying instance and in instance segmentation the instance as well as a segmentation mask for an object is predicted. \cite {instance_vs_semantic_fig}\relax }}{27}{}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces The inverted residual block. A $1 \times 1$ convolution with non-linear activation followed by a depthwise separable convolution and a linear $1 \times 1$ convolution with residual connection to the input. The residual connection is here additive, i.e. the input gets added to the output of the linear $1 \times 1$ convolution.\relax }}{29}{}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces An example drawing of a hypergraph with its corresponding adjacency matrix. The hypergraph is defined as: $H = (V, E)$, $V = \{v1, v2, v3, v4\}$, $E = \{e1, e2\}$, with $e1 = \{v1, v2, v3\}$, $e2 = \{v3, v4\}$. In the adjacency matrix a row corresponds to a hyperedge and each column to a vertex. When a vertex is present in a hyperedge it has a 1 as an entry in the matrix, when a vertex is not present it has a 0.\relax }}{32}{}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Example of a precision-recall curve, where precision and recall were calculated for different \ac {IoU} thresholds and sorted and plotted by their recall values \cite {map_article}. The \ac {AP} is the area under the curve.\relax }}{33}{}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Example predictions of YOLO (left) and MobileNetV2-UNet (right). YOLO predicts a bounding box around each component with its corresponding class, while MobileNetV2-UNet predicts a segmentation mask a binary fashion of the whole \ac {ECD} drawing, including \ac {ECC} annotations. Primary segmentation is needed to remove the checkered background from the image.\relax }}{39}{}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces The results of the initial learning rate search shown on the validation set, as the mean of the mAPs of three separate training runs.\relax }}{44}{}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces The results of the offline augmentation with the different offline augmentation configurations compared with the results of the best performing learning rate (baseline). When rotation and flip are enabled simultaneously the flipped image also gets rotated three times by 90\textdegree . Results are given as the mean of the mAP of three separate training runs.\relax }}{45}{}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
