\addvspace {10\p@ }
\contentsline {figure}{\numberline {1.1}{\ignorespaces A drawing of an \ac {ECD} on a grid paper background with its \acp {ECC} and annotations.\relax }}{2}{figure.caption.5}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces All used \acp {ECC} in this thesis in German notation: 1. Voltage Source, 2. Current Source, 3. Resistor, 4. Inductor, 5. Capacitor, 6. Diode, 7. Ground\relax }}{9}{figure.caption.16}%
\contentsline {figure}{\numberline {2.2}{\ignorespaces A MLP with two hidden layers (two neurons in the first and one in the last), each input gets multiplied with each weight of each neuron, summed up and fed into an activation function to produce the input for the next layer, where this process is repeated.\relax }}{14}{figure.caption.25}%
\contentsline {figure}{\numberline {2.3}{\ignorespaces Example convolution of a 4x4 input (blue) with a 3x3 kernel (dark blue) and a stride of 1, resulting in a 2x2 output (cyan) \cite {conv_arithmetic}\relax }}{18}{figure.caption.35}%
\contentsline {figure}{\numberline {2.4}{\ignorespaces Example of results obtained through the Selective Search algorithm (top) with increasing region scale from left to right and bounding boxes drawn around those regions (bottom). Selective Search produces sub-segmentations of objects in an image, considering size, color, texture and shape based features for the grouping of the regions \cite {selective_search}.\relax }}{22}{figure.caption.43}%
\contentsline {figure}{\numberline {2.5}{\ignorespaces Bounding box calculation in the YOLOv4 network based on a prior anchor box \cite {yolov2}. The $b_*$ indicate the final prediction, $p_*$ indicate parameters of the prior bounding box and $c_*$ indicate the prior bounding box spatial offset based on the current cell. The final center coordinate offset is predicted non-linearly with a sigmoid function, while the final width and height are predicted linearly, as it is done in \cite {fast_rcnn} and \cite {faster_rcnn}.\relax }}{29}{figure.caption.61}%
\contentsline {figure}{\numberline {2.6}{\ignorespaces The difference between object detection, semantic segmentation and instance segmentation. In object detection the instance with a rough estimate (bounding box) is predicted, in semantic segmentation a segmentation mask for an object is predicted without considering the underlying instance and in instance segmentation the instance as well as a segmentation mask for an object is predicted \cite {instance_vs_semantic_fig}.\relax }}{34}{figure.caption.66}%
\contentsline {figure}{\numberline {2.7}{\ignorespaces (a) The inverted residual block. A $1 \times 1$ convolution with non-linear activation followed by a depthwise separable convolution and a linear $1 \times 1$ convolution with residual connection to the input. The residual connection is here additive, i.e. the input gets added to the output of the linear $1 \times 1$ convolution. It is called inverted, due to the expansion inside the block, while in the traditional residual block (b) the input gets expanded when it leaves the block \cite {mnetv2}.\relax }}{36}{figure.caption.68}%
\contentsline {figure}{\numberline {2.8}{\ignorespaces An example drawing of a hypergraph with its corresponding adjacency matrix. The hypergraph is defined as: $\mathbf {H} = (\mathbf {V}, \mathbf {E})$, $\mathbf {V} = \{v_1, v_2, v_3, v_4\}$, $\mathbf {E} = \{\mathbf {e_1}, \mathbf {e_2}\}$, with $\mathbf {e_1} = \{v_1, v_2, v_3\}$, $\mathbf {e_2} = \{v_3, v_4\}$. In the adjacency matrix a row corresponds to a hyperedge and each column to a vertex. When a vertex is present in a hyperedge it has a 1 as an entry in the matrix, when a vertex is not present it has a 0 \cite {hypergraph_adjacency_my}.\relax }}{38}{figure.caption.70}%
\contentsline {figure}{\numberline {2.9}{\ignorespaces Example of a precision-recall curve, where precision and recall were calculated for different \ac {IoU} thresholds and sorted and plotted by their recall values \cite {map_article}. The \ac {AP} is the area under the curve.\relax }}{40}{figure.caption.81}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {3.1}{\ignorespaces Example segmentation label mask (left) and bounding boxes labels (right).\relax }}{46}{figure.caption.87}%
\contentsline {figure}{\numberline {3.2}{\ignorespaces An example visual labeling helper image (top), shown with the index of the respective bounding box in the YOLO label file, together with the corresponding hypergraph adjacency matrix (bottom). Two columns in the matrix correspond to one \ac {ECC}, each column to one orientation, where the first column can either be the left or top orientation and the second column be the right or bottom orientation. The last column in the table further shows the string representation of an edge, which acts as the input for the labeling tool. For instance ``1r,0t,4t'' means that 1 right, 0 top and 4 top are connected to each other through a hyperedge.\relax }}{47}{figure.caption.89}%
\contentsline {figure}{\numberline {3.3}{\ignorespaces The six-stage pipeline presented in this thesis. Stage 1 shows the results of the object detection with \ac {YOLO} and stage 2 the segmentation results with the \ac {MUnet}. Stage 3-5 are postprocessing stages, where the topology is created, the annotations are matched to their respective \ac {ECC} and the characters of the textual annotations are recognized. The last stage is the conversion stage, where the gathered information is embedded into the LTspice schematic file format.\relax }}{50}{figure.caption.94}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces An overview of the conducted experiments with the \ac {YOLO}. Best parameters which were obtained from a previous experiment were used in the following experiment.\relax }}{58}{figure.caption.102}%
\contentsline {figure}{\numberline {4.2}{\ignorespaces The results of the initial learning rate search shown on the validation set, with the mean and standard deviation of the \acp {mAP} over three separate training runs.\relax }}{59}{figure.caption.103}%
\contentsline {figure}{\numberline {4.3}{\ignorespaces The results of the offline augmentation with the different offline augmentation configurations compared with the results of the best performing learning rate (baseline). When rotation and flip are enabled simultaneously the flipped image also gets rotated three times by 90\textdegree . Results are given with the mean and standard deviation of the \acp {mAP} of three separate training runs.\relax }}{60}{figure.caption.105}%
\contentsline {figure}{\numberline {4.4}{\ignorespaces Results of the online augmentation experiment compared to the baseline which was established in the offline augmentation experiment. Each augmentation shows a clear increase in \ac {mAP} in comparison to the baseline. Results are given with the mean and standard deviation of the \acp {mAP} of three separate training runs.\relax }}{61}{figure.caption.106}%
\contentsline {figure}{\numberline {4.5}{\ignorespaces Results of the grid search shown for all loss functions, learning rates and batch sizes. Independent of the loss / learning rate combination a batch size of 32 performed consistently worse than a batch size of 64.\relax }}{63}{figure.caption.108}%
\contentsline {figure}{\numberline {4.6}{\ignorespaces Results of the YOLO grid search for all used loss functions and learning rates shown for batch size 64 on the validation dataset.\relax }}{63}{figure.caption.109}%
\contentsline {figure}{\numberline {4.7}{\ignorespaces Different input sizes tested after training on the validation set.\relax }}{64}{figure.caption.111}%
\contentsline {figure}{\numberline {4.8}{\ignorespaces Results of the voting based thresholding approach to improve model performance, shown on the validation set for all possible voting thresholds.\relax }}{66}{figure.caption.114}%
\contentsline {figure}{\numberline {4.9}{\ignorespaces The final results of the tuning experiment performed on the validation set, presented also with the performance on the test dataset. Specific explanation of the experiments with the optimal obtained parameters can be found in table \ref {tab:yolo_tuning_combined_results}.\relax }}{67}{figure.caption.115}%
\contentsline {figure}{\numberline {4.10}{\ignorespaces An overview of the conducted experiments with the \ac {MUnet}. Best parameters which were obtained from a previous experiment were used in the following experiment.\relax }}{68}{figure.caption.116}%
\contentsline {figure}{\numberline {4.11}{\ignorespaces The results of the initial learning rate search shown on the validation set, with the mean and standard deviation of the F1-Score over three separate training runs.\relax }}{69}{figure.caption.117}%
\contentsline {figure}{\numberline {4.12}{\ignorespaces The results of the offline augmentation experiment shown on the validation set, as the mean F1-Score of three separate training runs.\relax }}{69}{figure.caption.119}%
\contentsline {figure}{\numberline {4.13}{\ignorespaces The results of the online augmentation experiment shown on the validation set, as the mean F1-Score of three separate training runs.\relax }}{70}{figure.caption.121}%
\contentsline {figure}{\numberline {4.14}{\ignorespaces The results of the selected \ac {MUnet} networks with a batch size of 32.\relax }}{73}{figure.caption.122}%
\contentsline {figure}{\numberline {4.15}{\ignorespaces The results of the selected \ac {MUnet} networks with a batch size of 64.\relax }}{74}{figure.caption.123}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {5.1}{\ignorespaces Overview of the evaluation pipeline. Evaluation is split into classification evaluation of bounding boxes, topology evaluation and matching evaluation.\relax }}{76}{figure.caption.124}%
\addvspace {10\p@ }
\contentsline {figure}{\numberline {A.1}{\ignorespaces The results of the \ac {DIoU}-\ac {NMS} parameter tuning. All possible combinations of score threshold and \ac {IoU} threshold were evaluated on the validation set. The best performing combination is the one with a score threshold of 0.1 and a \ac {IoU} threshold of 0.45.\relax }}{124}{figure.caption.138}%
\contentsline {figure}{\numberline {A.2}{\ignorespaces The results of the \ac {WBF} parameter tuning. All possible combinations of score threshold and \ac {IoU} threshold were evaluated on the validation set. The best performing combination is the one with a score threshold of 0.15 and an \ac {IoU} threshold of 0.25.\relax }}{125}{figure.caption.139}%
\contentsline {figure}{\numberline {A.3}{\ignorespaces The results of the \ac {WBF} tuning with \ac {TTA}. All possible combinations of score threshold and \ac {IoU} threshold were evaluated on the validation set. The best performing combination is the one with a score threshold of 0.1 and an \ac {IoU} threshold of 0.45.\relax }}{126}{figure.caption.140}%
\contentsline {figure}{\numberline {B.1}{\ignorespaces F1-Score results of the \ac {MUnet} grid search experiment shown on the full validation data. Results are shown combined for the loss and batch size against the learning rate.\relax }}{127}{figure.caption.141}%
\contentsline {figure}{\numberline {B.2}{\ignorespaces Recall results of the \ac {MUnet} grid search experiment shown on the full validation data. Results are shown combined for the loss and batch size against the learning rate.\relax }}{128}{figure.caption.142}%
\contentsline {figure}{\numberline {B.3}{\ignorespaces Precision results of the \ac {MUnet} grid search experiment shown on the full validation data. Results are shown combined for the loss and batch size against the learning rate.\relax }}{129}{figure.caption.143}%
\contentsline {figure}{\numberline {B.4}{\ignorespaces F1-Score results of the \ac {MUnet} grid search experiment shown validation data, for checkered images only. Results are shown combined for the loss and batch size against the learning rate.\relax }}{130}{figure.caption.144}%
\contentsline {figure}{\numberline {B.5}{\ignorespaces Recall results of the \ac {MUnet} grid search experiment shown validation data, for checkered images only. Results are shown combined for the loss and batch size against the learning rate.\relax }}{131}{figure.caption.145}%
\contentsline {figure}{\numberline {B.6}{\ignorespaces Precision results of the \ac {MUnet} grid search experiment shown validation data, for checkered images only. Results are shown combined for the loss and batch size against the learning rate.\relax }}{132}{figure.caption.146}%
